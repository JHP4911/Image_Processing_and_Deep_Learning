{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tree_Detection_Keras_RetinaNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6D_Wz3h5ILS",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup\n",
        "Download and install in Colab required packages and import libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPFpERt0TOIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, shutil, urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "#import rasterio\n",
        "#from keras_unet.models import satellite_unet\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive//My Drive/ForFun')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PdMj4Tn3tgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "!git clone https://github.com/fizyr/keras-retinanet.git\n",
        "%cd keras-retinanet/\n",
        "!pip install .\n",
        "!python setup.py build_ext --inplace\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UI7XYyxyJcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import urllib\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwgO7a4osxhG",
        "colab_type": "text"
      },
      "source": [
        "## Delete certain type of files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxeonLTwsXmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "%cd keras-retinanet/dataset\n",
        "\n",
        "files = os.listdir()\n",
        "tifs = [i for i in files if i.endswith('.xml')]\n",
        "for f in tifs:\n",
        "    os.remove(f)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7J7ZYg-tCZ0",
        "colab_type": "text"
      },
      "source": [
        "## Convert csv to PlumsVOC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktbLQv_atvkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install pascal_voc_writer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMqQTVB5tJK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive//My Drive/ForFun/keras-retinanet')\n",
        "\n",
        "df = pd.read_csv(\"../annotations.csv\")\n",
        "sh = df.shape\n",
        "print(sh)\n",
        "print(df.head(5))\n",
        "imgs = df['img'].unique()\n",
        "len(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dfiu_CHvvaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs[0]\n",
        "imgs[0][0:-3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PInAgycduBHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive//My Drive/ForFun/keras-retinanet')\n",
        "\n",
        "from pascal_voc_writer import Writer\n",
        "\n",
        "for i in range(len(imgs)):\n",
        "    \n",
        "    dfsb = df[df.img.eq(imgs[i])]\n",
        "    dfsb = dfsb.reset_index()\n",
        "    shape = dfsb.shape\n",
        "    \n",
        "    nm = imgs[i]\n",
        "    writer = Writer(nm, 200, 200)\n",
        "    \n",
        "    for j in range(shape[0]):\n",
        "        \n",
        "        xmin = dfsb['xmin'][j]\n",
        "        xmax = dfsb['xmax'][j]\n",
        "        ymin = dfsb['ymin'][j]\n",
        "        ymax = dfsb['ymax'][j]\n",
        "        \n",
        "        writer.addObject(dfsb['class'][j],xmin, ymin, xmax, ymax)\n",
        "    \n",
        "    nm2 = dfsb['img'][1][0:-3] + 'xml'\n",
        "    writer.save(nm2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXWCAtcTXKiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGtn3JW6Mig8",
        "colab_type": "text"
      },
      "source": [
        "# Training Model\n",
        "\n",
        "Download pretrained model and run training.\n",
        "\n",
        "In the next cell choose one option:\n",
        "\n",
        "1.   download Fizyr Resnet50 pretrained model\n",
        "2.   download your custom pretrained model, to continue previous training epochs\n",
        "\n",
        "In the last cell optionally export trained model to Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXQzV1yhz3jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive//My Drive/ForFun/keras-retinanet')\n",
        "\n",
        "PRETRAINED_MODEL = './snapshots/_pretrained_model2.h5'\n",
        "\n",
        "#### OPTION 1: DOWNLOAD INITIAL PRETRAINED MODEL FROM FIZYR ####\n",
        "URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\n",
        "urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n",
        "\n",
        "#print('Downloaded pretrained model to ' + PRETRAINED_MODEL)\n",
        "\n",
        "#PRETRAINED_MODEL = './snapshots/resnet50_csv_50.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-uzSUUzX6At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/ForFun/keras-retinanet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ1Zjet7xO0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras_resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srmfQH11xCTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras_retinanet\n",
        "import keras_resnet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "#from keras_retinanet.utils.gpu import setup_gpu\n",
        "from keras_retinanet.models import load_model\n",
        "# import miscellaneous modules\n",
        "import cv2\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bexsEvq_zb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 8 --steps 200 --epochs 100 csv annotations.csv classes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwDP6tltvlTG",
        "colab_type": "text"
      },
      "source": [
        "#Convert trained model into inference model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-RphoZ0cYCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/ForFun/keras-retinanet')\n",
        "#!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_10.h5 snapshots/model10.h5\n",
        "#!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_20.h5 snapshots/model20.h5\n",
        "#!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_30.h5 snapshots/model30.h5\n",
        "#!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_40.h5 snapshots/model40.h5\n",
        "#!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_50.h5 snapshots/model50.h5\n",
        "!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_60.h5 snapshots/model60.h5\n",
        "!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_69.h5 snapshots/model70.h5\n",
        "!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_80.h5 snapshots/model80.h5\n",
        "!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_90.h5 snapshots/model90.h5\n",
        "!python3 keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_100.h5 snapshots/model100.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l41Etk-NdFOp",
        "colab_type": "text"
      },
      "source": [
        "# Run trained models on test/train data to get mAP\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh2tor9j3YCn",
        "colab_type": "text"
      },
      "source": [
        "## On test dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr4yXiJGdhZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval1 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model10.h5\n",
        "eval2 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model20.h5\n",
        "eval3 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model30.h5\n",
        "eval4 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model40.h5\n",
        "eval5 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model50.h5\n",
        "\n",
        "eval6 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model60.h5\n",
        "eval7 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model70.h5\n",
        "eval8 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model80.h5\n",
        "eval9 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model90.h5\n",
        "eval10 = !python3 keras_retinanet/bin/evaluate.py csv testAnnotations.csv classes.csv snapshots/model100.h5\n",
        "eva_ls = []\n",
        "\n",
        "for i in range(10):\n",
        "  nm = 'eval'+ str(i+1) \n",
        "  eval = globals()[nm]\n",
        "  n = len(eval)\n",
        "  eva_ls.append(eval[n-1][0:10])\n",
        "\n",
        "eva_ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEey-BvPClnu",
        "colab_type": "text"
      },
      "source": [
        "## On train dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h0G1VoFl8XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval1 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model10.h5\n",
        "eval2 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model20.h5\n",
        "eval3 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model30.h5\n",
        "eval4 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model40.h5\n",
        "eval5 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model50.h5\n",
        "\n",
        "eval6 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model60.h5\n",
        "eval7 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model70.h5\n",
        "eval8 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model80.h5\n",
        "eval9 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model90.h5\n",
        "eval10 = !python3 keras_retinanet/bin/evaluate.py csv annotations.csv classes.csv snapshots/model100.h5\n",
        "\n",
        "eva_ls2 = []\n",
        "\n",
        "for i in range(10):\n",
        "  nm = 'eval'+ str(i+1) \n",
        "  eval = globals()[nm]\n",
        "  n = len(eval)\n",
        "  eva_ls2.append(eval[n-1][0:10])\n",
        "\n",
        "eva_ls2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfsj1KOVzTdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "THRES_SCORE = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYyfa8yniJiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session():\n",
        "    config = tf.compat.v1.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.compat.v1.Session(config=config)\n",
        "\n",
        "# use this environment flag to change which GPU to use\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "tf.compat.v1.keras.backend.set_session(get_session())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1QimaHHh_M0",
        "colab_type": "text"
      },
      "source": [
        "# Load best model for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkewNh9UiOs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/ForFun/keras-retinanet')\n",
        "\n",
        "'''\n",
        "PRETRAINED_MODEL = './snapshots/resnet50_csv_20.h5'\n",
        "\n",
        "from keras_retinanet.models import load_model\n",
        "model = load_model(PRETRAINED_MODEL, backbone_name='resnet50')\n",
        "model = models.convert_model(model)\n",
        "'''\n",
        "model = load_model('./snapshots/model60.h5')\n",
        "\n",
        "CLASSES_FILE = \"classes.csv\"\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = pd.read_csv(CLASSES_FILE,header=None).T.loc[0].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g98rQIOGmifh",
        "colab_type": "text"
      },
      "source": [
        "## Load image for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdPstmOOmb17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load imagery\n",
        "image_dir = \"test85/\"\n",
        "\n",
        "image_list = []\n",
        "for root, dirs, files in os.walk(image_dir):  \n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.jpg')):\n",
        "            image_list.append(image_dir + filename)\n",
        "print(len(image_list))\n",
        "image_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apc4cZTnx8sJ",
        "colab_type": "text"
      },
      "source": [
        "## Run detections on all tiles\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9PUhovmqio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_score = 0.426 # this is the CNN's confidence that the detection is correct\n",
        "detection_iterations = 82 # max number of images to visualize\n",
        "\n",
        "visualize = True\n",
        "\n",
        "detections = {}\n",
        "total_time = 0\n",
        "\n",
        "count = 0\n",
        "shuffle(image_list)\n",
        "\n",
        "for image_path in image_list:\n",
        "    if count > detection_iterations:\n",
        "        break\n",
        "    else:\n",
        "        count +=1\n",
        "        \n",
        "    image = read_image_bgr(image_path)\n",
        "    tileID = []\n",
        "\n",
        "    if visualize:\n",
        "        # copy to draw on\n",
        "        draw = image.copy()\n",
        "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(image)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    total_time += time.time() - start\n",
        "\n",
        "\n",
        "    # correct for image scale\n",
        "    boxes /= scale\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        detections[image_path] = []\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        # scores are sorted so we can break\n",
        "        if score < min_score:\n",
        "            break\n",
        "\n",
        "        #print(score)\n",
        "        #print(box)\n",
        "\n",
        "        # TODO this does create a slight error in the boxes, might be worth doing something like\n",
        "        # list(map(str, box) but then would need to cast on the other end back to float\n",
        "        b = box.astype(int)\n",
        "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
        "\n",
        "        if visualize:\n",
        "            color = label_color(label)\n",
        "\n",
        "            # b = box.astype(int)\n",
        "            draw_box(draw, b, color=color)\n",
        "\n",
        "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "            draw_caption(draw, b, caption)\n",
        "\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        if visualize:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(draw)\n",
        "            plt.show()\n",
        "    \n",
        "print(\"Finished, time per image:\", total_time/len(image_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLlEm4lxK60J",
        "colab_type": "text"
      },
      "source": [
        "## Write detections to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4b5Uml1um9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(MyEncoder, self).default(obj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKR1f1YBuo06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('prediction20.json', 'w') as fp:\n",
        "    json.dump(detections, fp, cls=MyEncoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYVHuqZdxzuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwHR0uoMbMWn",
        "colab_type": "text"
      },
      "source": [
        "# Use models trained with different epoch for prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa9_-IZ6h69o",
        "colab_type": "text"
      },
      "source": [
        "## Load all packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmuF-ceeh495",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session():\n",
        "    config = tf.compat.v1.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.compat.v1.Session(config=config)\n",
        "\n",
        "# use this environment flag to change which GPU to use\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "tf.compat.v1.keras.backend.set_session(get_session())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG8F4IPpbVZZ",
        "colab_type": "text"
      },
      "source": [
        "## Load image for testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMc4nB7jbf3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load imagery\n",
        "os.chdir('/content/drive/My Drive/ForFun/keras-retinanet')\n",
        "image_dir = \"test85/\"\n",
        "\n",
        "image_list = []\n",
        "for root, dirs, files in os.walk(image_dir):  \n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.jpg')):\n",
        "            image_list.append(image_dir + filename)\n",
        "print(len(image_list))\n",
        "print(image_list)\n",
        "\n",
        "CLASSES_FILE = \"classes.csv\"\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = pd.read_csv(CLASSES_FILE,header=None).T.loc[0].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvnNyvkggOa7",
        "colab_type": "text"
      },
      "source": [
        "## Define functions for prediction and write results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZsO5-kdRLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_retinanet.models import load_model\n",
        "\n",
        "def pred(model_nm, image_list, min_score, write_nm):\n",
        "\n",
        "  model = load_model(model_nm, backbone_name='resnet50')\n",
        "\n",
        "  min_score = min_score # this is the CNN's confidence that the detection is correct\n",
        "  \n",
        "  detections = {}\n",
        "  total_time = 0\n",
        "  count = 0\n",
        "  shuffle(image_list)\n",
        "  \n",
        "  for image_path in image_list:\n",
        "        \n",
        "    image = read_image_bgr(image_path)\n",
        "    tileID = []\n",
        "\n",
        "    \n",
        "    # preprocess image for network\n",
        "    image = preprocess_image(image)\n",
        "    image, scale = resize_image(image)\n",
        "\n",
        "    # process image\n",
        "    start = time.time()\n",
        "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "    total_time += time.time() - start\n",
        "\n",
        "\n",
        "    # correct for image scale\n",
        "    boxes /= scale\n",
        "    if any(score >= min_score for score in scores[0]):\n",
        "        detections[image_path] = []\n",
        "\n",
        "    # visualize detections\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        # scores are sorted so we can break\n",
        "        if score < min_score:\n",
        "            break\n",
        "\n",
        "        #print(score)\n",
        "        #print(box)\n",
        "\n",
        "        # TODO this does create a slight error in the boxes, might be worth doing something like\n",
        "        # list(map(str, box) but then would need to cast on the other end back to float\n",
        "        b = box.astype(int)\n",
        "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
        "\n",
        "    class MyEncoder(json.JSONEncoder):\n",
        "      def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(MyEncoder, self).default(obj)\n",
        "\n",
        "    with open(write_nm, 'w') as fp:\n",
        "      json.dump(detections, fp, cls=MyEncoder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0_QakmtgdHh",
        "colab_type": "text"
      },
      "source": [
        "## Loop for predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKZN66A4gpIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "  model_nm = './snapshots/model'+str((i+1)*10) + '.h5'\n",
        "  min_score=0.426\n",
        "  write_nm = \"prediction\" + str((i+1)*10) + '.json'\n",
        "  pred(model_nm, image_list, min_score, write_nm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ-O9HUq2Q8D",
        "colab_type": "text"
      },
      "source": [
        "# Run detection on uploaded data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWSHqP1KTHxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_inference(img_path):\n",
        "  image = read_image_bgr(img_infer)\n",
        "\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "\n",
        "  # process image\n",
        "  start = time.time()\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - start)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < THRES_SCORE:\n",
        "          break\n",
        "\n",
        "      color = label_color(label)\n",
        "\n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "\n",
        "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "      print(caption)\n",
        "      draw_caption(draw, b, caption)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(draw)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_AoWG4lHFME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "img_infer = list(uploaded)[0]\n",
        "\n",
        "print('Running inference on: ' + img_infer)\n",
        "img_inference(img_infer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaCfLE9ZYLB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}